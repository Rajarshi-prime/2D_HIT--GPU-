{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "kernel_code = r'''\n",
    "// Double precision atomicAdd implementation\n",
    "__device__ double atomicAdd_double(double* address, double val)\n",
    "{\n",
    "    unsigned long long int* address_as_ull = (unsigned long long int*)address;\n",
    "    unsigned long long int old = *address_as_ull;\n",
    "    unsigned long long int assumed;\n",
    "    do {\n",
    "        assumed = old;\n",
    "        old = atomicCAS(address_as_ull, assumed,\n",
    "                       __double_as_longlong(val + __longlong_as_double(assumed)));\n",
    "    } while (assumed != old);\n",
    "    return __longlong_as_double(old);\n",
    "}\n",
    "\n",
    "extern \"C\" __global__ void process_combinations(\n",
    "    const double* Mmat,\n",
    "    const double* poly,\n",
    "    const int* idx,\n",
    "    const double* u_field,double* umat,\n",
    "    int order,\n",
    "    int N,\n",
    "    int batch_size\n",
    ") {\n",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int total_combinations = order * order;\n",
    "    \n",
    "    if (tid < total_combinations) {\n",
    "        int i = tid / order;\n",
    "        int j = tid % order;\n",
    "        \n",
    "        // Process one i,j combination per thread\n",
    "        for (int b = 0; b < batch_size; b++) {\n",
    "            double temparr = 0.0;\n",
    "            \n",
    "            // Manual einsum computation\n",
    "            for (int p = 0; p < 4; p++) {\n",
    "                for (int q = 0; q < 4; q++) {\n",
    "                    temparr += Mmat[i * 4 + p] * Mmat[j * 4 + q] * \n",
    "                              poly[b * 8 + p] * poly[b * 8 + 4 + q];\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            // Compute indices\n",
    "            int slx = (idx[b * 2] - 1 + i) % N;\n",
    "            int sly = (idx[b * 2 + 1] - 1 + j) % N;\n",
    "            \n",
    "            // Update umat using custom atomicAdd for double precision\n",
    "            atomicAdd_double(&umat[b * 2], u_field[slx * N * 2 + sly * 2] * temparr);\n",
    "            atomicAdd_double(&umat[b * 2 + 1], u_field[slx * N * 2 + sly * 2 + 1] * temparr);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "def parallel_computation_cuda(order, Mmat, poly, idx, N, u_field, threads_per_block=256):\n",
    "    # Ensure all inputs are float64\n",
    "    Mmat_gpu = cp.asarray(Mmat, dtype=cp.float64)\n",
    "    poly_gpu = cp.asarray(poly, dtype=cp.float64)\n",
    "    idx_gpu = cp.asarray(idx, dtype=cp.int32)\n",
    "    u_field_gpu = cp.asarray(u_field, dtype=cp.float64)\n",
    "    \n",
    "    batch_size = poly_gpu.shape[0]\n",
    "    umat_gpu = cp.zeros((batch_size, 2), dtype=cp.float64)\n",
    "    \n",
    "    # Compile the kernel\n",
    "    module = cp.RawModule(code=kernel_code)\n",
    "    kernel = module.get_function('process_combinations')\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    total_threads = order * order\n",
    "    blocks = (total_threads + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    # Launch kernel\n",
    "    kernel((blocks,), (threads_per_block,),\n",
    "          (Mmat_gpu, poly_gpu, idx_gpu, u_field_gpu, umat_gpu,\n",
    "           cp.int32(order), cp.int32(N), cp.int32(batch_size)))\n",
    "    \n",
    "    return umat_gpu\n",
    "\n",
    "# Example usage:\n",
    "# result = parallel_computation_cuda(order, Mmat, poly, idx, N, u_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 200\n",
    "N = 1024\n",
    "Np = N//3\n",
    "Mat = cp.random.random((order, order)).astype(cp.float64)\n",
    "poly = cp.random.random((Np,2,order),dtype=cp.float64)\n",
    "idx = cp.random.randint(0, N, (Np,2), dtype=int)\n",
    "u_field = cp.random.random((N, N, 2)).astype(cp.float64)*10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 655 µs, sys: 162 µs, total: 817 µs\n",
      "Wall time: 828 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d1 = parallel_computation_cuda(order, Mat, poly, idx, N, u_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_func(order, Mmat, poly, idx, N, u_field):\n",
    "    umat = idx*0.0\n",
    "    for i in range(order):\n",
    "        for j in range(order):\n",
    "            temparr = cp.einsum('p,q,...p,...q->...',Mmat[i],Mmat[j],poly[...,0,:],poly[...,1,:]) #! For saving computations\n",
    "            slx = (idx[:,0]-1 + i)%N #! For saving computations\n",
    "            sly= (idx[:,1]-1 + j)%N #! For saving computations\n",
    "            \n",
    "            umat  += u_field[slx,sly,...]*temparr[:,None]\n",
    "    return umat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 343 ms, total: 1.85 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d2 = normal_func(order, Mat, poly, idx, N, u_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import itertools\n",
    "\n",
    "# Approach 1: Using concurrent.futures ThreadPoolExecutor\n",
    "def process_ij_combination(args):\n",
    "    i, j, Mmat_gpu, poly_gpu, idx_gpu, N, u_field_gpu = args\n",
    "    batch_size = poly_gpu.shape[0]\n",
    "    \n",
    "    # Compute temparr using einsum\n",
    "    temparr = cp.einsum('p,q,np,nq->n',\n",
    "                       Mmat_gpu[i],\n",
    "                       Mmat_gpu[j],\n",
    "                       poly_gpu[...,0,:],\n",
    "                       poly_gpu[...,1,:])\n",
    "    \n",
    "    # Compute indices\n",
    "    slx = (idx_gpu[:,0] - 1 + i) % N\n",
    "    sly = (idx_gpu[:,1] - 1 + j) % N\n",
    "    \n",
    "    # Get u_field values and multiply with temparr\n",
    "    return u_field_gpu[slx, sly] * temparr[:,None]\n",
    "\n",
    "def parallel_computation_threads(order, Mmat, poly, idx, N, u_field):\n",
    "    # Move data to GPU once\n",
    "    Mmat_gpu = cp.asarray(Mmat)\n",
    "    poly_gpu = cp.asarray(poly)\n",
    "    idx_gpu = cp.asarray(idx)\n",
    "    u_field_gpu = cp.asarray(u_field)\n",
    "    \n",
    "    # Initialize output array\n",
    "    batch_size = poly_gpu.shape[0]\n",
    "    umat_gpu = cp.zeros((batch_size, 2), dtype=poly_gpu.dtype)\n",
    "    \n",
    "    # Create all combinations of i,j\n",
    "    ij_combinations = [(i, j, Mmat_gpu, poly_gpu, idx_gpu, N, u_field_gpu) \n",
    "                      for i, j in itertools.product(range(order), range(order))]\n",
    "    \n",
    "    # Process combinations in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_ij_combination, ij_combinations))\n",
    "    \n",
    "    # Sum all results\n",
    "    for result in results:\n",
    "        umat_gpu += result\n",
    "    \n",
    "    return cp.asnumpy(umat_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
